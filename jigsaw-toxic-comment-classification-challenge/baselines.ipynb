{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic-Comments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voNc7cygJXqj",
        "colab_type": "text"
      },
      "source": [
        "# Toxic Comment Classification Challenge\n",
        "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEPTh8tFJcqf",
        "colab_type": "text"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvU8gzBTJSF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzPZCWTxih10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDAJ4qC4J6ED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "3a2ffc52-038b-4282-9295-270a26dc459f"
      },
      "source": [
        "!pip install kaggle\n",
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge\n",
        "!mkdir data\n",
        "!unzip train.csv.zip -d data/\n",
        "!unzip test.csv.zip  -d data/\n",
        "!unzip test_labels.csv.zip  -d data/\n",
        "!unzip sample_submission.csv.zip  -d data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.9.11)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.39M [00:00<?, ?B/s]\n",
            "100% 1.39M/1.39M [00:00<00:00, 93.7MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 73% 17.0M/23.4M [00:00<00:00, 19.2MB/s]\n",
            "100% 23.4M/23.4M [00:00<00:00, 28.3MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 34% 9.00M/26.3M [00:00<00:01, 9.26MB/s]\n",
            "100% 26.3M/26.3M [00:00<00:00, 28.6MB/s]\n",
            "Downloading test_labels.csv.zip to /content\n",
            "  0% 0.00/1.46M [00:00<?, ?B/s]\n",
            "100% 1.46M/1.46M [00:00<00:00, 99.4MB/s]\n",
            "Archive:  train.csv.zip\n",
            "  inflating: data/train.csv          \n",
            "Archive:  test.csv.zip\n",
            "  inflating: data/test.csv           \n",
            "Archive:  test_labels.csv.zip\n",
            "  inflating: data/test_labels.csv    \n",
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: data/sample_submission.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApRqWvaMLkz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = 'data/train.csv'\n",
        "test_path = 'data/test.csv'\n",
        "test_labels_path = 'data/test_labels.csv'\n",
        "subm_path = 'data/sample_submission.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd8Jl5wmLEF1",
        "colab_type": "text"
      },
      "source": [
        "## NBSVM (Linear Baseline)\n",
        "https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFoVcAuTD3x2",
        "colab_type": "text"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVcLYgJQD3Pz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "1eff3410-8eda-4617-d7b7-c68a3e04be00"
      },
      "source": [
        "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "df_train = pd.read_csv(train_path)\n",
        "df_test = pd.read_csv(test_path)\n",
        "df_test_labels = pd.read_csv(test_labels_path)\n",
        "df_test_labels = df_test_labels.set_index('id')\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqEG9zkcLaLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd, numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmC55Mz9Oya9",
        "colab_type": "text"
      },
      "source": [
        "### Sentence lengths & class distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3Szfhn_MKNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "63651d5b-f321-4c4c-b08b-53dfaa048fbb"
      },
      "source": [
        "comment_lens = df_train.comment_text.str.len()\n",
        "comment_lens.hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f01f5fbc978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nboaGJKmboSFJ6mZoSJK6GRqSpG7/Hw6s8kXxJy56AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osms_VWfMn4C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "e23b6641-8bdd-45bd-be8d-a747197188d5"
      },
      "source": [
        "df_train[label_cols].sum().sort_values(ascending=False).plot.bar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f01e45456a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAE0CAYAAADHQP+lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCyo5y99RX4N",
        "colab_type": "text"
      },
      "source": [
        "### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mlAJcfnNnjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "35d16852-2fb8-4172-f24d-c74cfb851cf2"
      },
      "source": [
        "import re, string\n",
        "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
        "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n",
        "\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    # tokenizer=TreebankWordTokenizer().tokenize,\n",
        "    tokenizer=tokenize,\n",
        "    #token_pattern=r'\\w{1,}',\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2), # include 1-grams and 2-grams\n",
        "    min_df=3, # only keep terms that appear in at least 2 documents\n",
        "    max_df=0.9,\n",
        "    max_features=None)\n",
        "\n",
        "x_train = vectorizer.fit_transform(df_train['comment_text'])\n",
        "x_test = vectorizer.transform(df_test['comment_text'])\n",
        "\n",
        "print(time.time() - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64.11209464073181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc3pc1fiRwyD",
        "colab_type": "text"
      },
      "source": [
        "### Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzOsEs8_PjN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy import sparse\n",
        "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
        "\n",
        "class NbSvmClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, C=1.0, dual=False, n_jobs=1):\n",
        "        self.C = C\n",
        "        self.dual = dual\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "    def predict(self, x):\n",
        "        # Verify that model has been fit\n",
        "        check_is_fitted(self, ['_r', '_clf'])\n",
        "        return self._clf.predict(x.multiply(self._r))\n",
        "\n",
        "    def predict_proba(self, x):\n",
        "        # Verify that model has been fit\n",
        "        check_is_fitted(self, ['_r', '_clf'])\n",
        "        return self._clf.predict_proba(x.multiply(self._r))\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        # Check that X and y have correct shape\n",
        "        y = y.values\n",
        "        x, y = check_X_y(x, y, accept_sparse=True)\n",
        "\n",
        "        def pr(x, y_i, y):\n",
        "            p = x[y==y_i].sum(0)\n",
        "            return (p+1) / ((y==y_i).sum()+1)\n",
        "\n",
        "        self._r = sparse.csr_matrix(np.log(pr(x,1,y) / pr(x,0,y)))\n",
        "\n",
        "        x_nb = x.multiply(self._r)\n",
        "        self._clf = LogisticRegression(C=self.C, dual=self.dual, n_jobs=self.n_jobs, solver='liblinear', max_iter=100).fit(x_nb, y)\n",
        "        return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24v75UGDR8uN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "1c764264-edb5-4cd3-ba0d-2c6772aef352"
      },
      "source": [
        "predictions = np.zeros((len(df_test), len(label_cols)))\n",
        "\n",
        "# | Train a seperate model for each dependent variable\n",
        "for i, label in enumerate(label_cols):\n",
        "    print('training', label)\n",
        "    model = NbSvmClassifier(C=4, dual=True)\n",
        "    model = model.fit(x_train, df_train[label])\n",
        "    \n",
        "    predictions[:,i] = model.predict_proba(x_test)[:,1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training toxic\n",
            "training severe_toxic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training obscene\n",
            "training threat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training insult\n",
            "training identity_hate\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dC_-3CtiutH",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDBoFdp4---O",
        "colab_type": "text"
      },
      "source": [
        "#### Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5DTTBle9xj5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "979b5633-a1ee-42db-c5ca-88f0e4f412cf"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "model = NbSvmClassifier(C=4, dual=True)\n",
        "\n",
        "scores = []\n",
        "for label in label_cols:\n",
        "    cv_score = np.mean(cross_val_score(model, x_train, df_train[label], cv=3, scoring='roc_auc'))\n",
        "    print(f'{label} score: {cv_score}', label)\n",
        "    scores.append(cv_score)\n",
        "    \n",
        "print('Total CV score is {}'.format(np.mean(scores)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic score: 0.9752707644224539 toxic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "severe_toxic score: 0.9791386669269002 severe_toxic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "obscene score: 0.98801672274422 obscene\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "threat score: 0.9799048702507259 threat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "insult score: 0.9772779775226743 insult\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "identity_hate score: 0.9700836621960347 identity_hate\n",
            "Total CV score is 0.9782821106771681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOg4_4NE_eSE",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluation on test-set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCaDoxpzVPdb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "782f9993-ecb5-4aed-e1be-6bc0a0d992a6"
      },
      "source": [
        "df_pred = pd.DataFrame(predictions, columns=label_cols)\n",
        "df_pred = pd.concat([df_test, df_pred], axis=1)\n",
        "df_pred = df_pred.set_index('id')\n",
        "\n",
        "df_pred.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>00001cee341fdb12</th>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "      <td>0.999996</td>\n",
              "      <td>0.056510</td>\n",
              "      <td>0.999964</td>\n",
              "      <td>0.002058</td>\n",
              "      <td>0.986571</td>\n",
              "      <td>0.362104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0000247867823ef7</th>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "      <td>0.006075</td>\n",
              "      <td>0.000966</td>\n",
              "      <td>0.004201</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.005512</td>\n",
              "      <td>0.000392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00013b17ad220c46</th>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "      <td>0.009947</td>\n",
              "      <td>0.000812</td>\n",
              "      <td>0.004720</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.004124</td>\n",
              "      <td>0.000283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00017563c3f7919a</th>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "      <td>0.001160</td>\n",
              "      <td>0.000283</td>\n",
              "      <td>0.001051</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00017695ad8997eb</th>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "      <td>0.016037</td>\n",
              "      <td>0.000392</td>\n",
              "      <td>0.001696</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0.002533</td>\n",
              "      <td>0.000301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       comment_text  ...  identity_hate\n",
              "id                                                                   ...               \n",
              "00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...  ...       0.362104\n",
              "0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...  ...       0.000392\n",
              "00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...  ...       0.000283\n",
              "00017563c3f7919a  :If you have a look back at the source, the in...  ...       0.000225\n",
              "00017695ad8997eb          I don't anonymously edit articles at all.  ...       0.000301\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leZWWpsXY-Wk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1be8baa6-5cf7-4787-9d88-581228c8bb8c"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "df_test_labels.head()\n",
        "\n",
        "idxs_used_for_eval = df_test_labels[df_test_labels['toxic'] != -1].index\n",
        "roc_auc_score(df_test_labels.loc[idxs_used_for_eval, label_cols], df_pred.loc[idxs_used_for_eval, label_cols])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9728629768281053"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JLzivucTb6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subm = pd.read_csv(subm_path)\n",
        "\n",
        "submid = pd.DataFrame({'id': subm[\"id\"]})\n",
        "submission = pd.concat([submid, pd.DataFrame(predictions, columns = label_cols)], axis=1)\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "!kaggle competitions submit -c jigsaw-toxic-comment-classification-challenge -f submission.csv -m \"nbsvm\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11kClB2i_raT",
        "colab_type": "text"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b99GTMP-FgTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4CeUBlzFTfz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a0ef2fe4-3b6e-4830-83dc-cce2236ca1fb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "keras = tf.keras\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93TwkNWlMx8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 300\n",
        "max_features = 100000\n",
        "max_len = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PECC6F0ZEltK",
        "colab_type": "text"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eCIoswSEmB5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "42622a98-cefe-4634-c3ee-2428e6ae7536"
      },
      "source": [
        "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "df = pd.read_csv(train_path)\n",
        "nr_train_samples = int(0.9*len(df))\n",
        "\n",
        "df_train = df.iloc[:nr_train_samples]\n",
        "df_val = df.iloc[nr_train_samples:]\n",
        "\n",
        "df_test = pd.read_csv(test_path)\n",
        "df_test_labels = pd.read_csv(test_labels_path)\n",
        "df_test = pd.concat([df_test, df_test_labels], axis=1)\n",
        "# df_test = df_test[df_test['toxic'] != -1]\n",
        "\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  00001cee341fdb12  ...            -1\n",
              "1  0000247867823ef7  ...            -1\n",
              "2  00013b17ad220c46  ...            -1\n",
              "3  00017563c3f7919a  ...            -1\n",
              "4  00017695ad8997eb  ...            -1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I94AIsXEp5R",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5mrNpykErUu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "18cc75eb-e87d-42cc-f5ec-76cb6f652147"
      },
      "source": [
        "text_col = \"comment_text\"\n",
        "\n",
        "df_train[text_col] = df_train[text_col].fillna(\"no comment\")\n",
        "df_val[text_col] = df_val[text_col].fillna(\"no comment\")\n",
        "df_test[text_col] = df_test[text_col].fillna(\"no comment\")\n",
        "\n",
        "df_train[text_col] = df_train[text_col].str.lower()\n",
        "df_val[text_col] = df_val[text_col].str.lower()\n",
        "df_test[text_col] = df_test[text_col].str.lower()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz8qNE6JNg1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words = max_features, lower = True)\n",
        "tokenizer.fit_on_texts(df_train[text_col])\n",
        "\n",
        "x_train = tokenizer.texts_to_sequences(df_train[text_col])\n",
        "y_train = df_train[label_cols].values\n",
        "\n",
        "x_val = tokenizer.texts_to_sequences(df_val[text_col])\n",
        "y_val = df_val[label_cols].values\n",
        "\n",
        "x_test = tokenizer.texts_to_sequences(df_test[text_col])\n",
        "y_test = df_test[label_cols].values\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen = max_len)\n",
        "x_val = pad_sequences(x_val, maxlen = max_len)\n",
        "x_test = pad_sequences(x_test, maxlen = max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFI0yt36CRua",
        "colab_type": "text"
      },
      "source": [
        "### Word Embeddings\n",
        "https://nlp.stanford.edu/projects/glove/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZE9xYbafCxES",
        "colab": {}
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "!unzip glove.840B.300d.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd7CnRN-C9p7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "0b7d6ece-5883-4627-e755-02954b98ce77"
      },
      "source": [
        "embedding_path = './glove.840B.300d.txt'\n",
        "\n",
        "!head -5 {embedding_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ", -0.082752 0.67204 -0.14987 -0.064983 0.056491 0.40228 0.0027747 -0.3311 -0.30691 2.0817 0.031819 0.013643 0.30265 0.0071297 -0.5819 -0.2774 -0.062254 1.1451 -0.24232 0.1235 -0.12243 0.33152 -0.006162 -0.30541 -0.13057 -0.054601 0.037083 -0.070552 0.5893 -0.30385 0.2898 -0.14653 -0.27052 0.37161 0.32031 -0.29125 0.0052483 -0.13212 -0.052736 0.087349 -0.26668 -0.16897 0.015162 -0.0083746 -0.14871 0.23413 -0.20719 -0.091386 0.40075 -0.17223 0.18145 0.37586 -0.28682 0.37289 -0.16185 0.18008 0.3032 -0.13216 0.18352 0.095759 0.094916 0.008289 0.11761 0.34046 0.03677 -0.29077 0.058303 -0.027814 0.082941 0.1862 -0.031494 0.27985 -0.074412 -0.13762 -0.21866 0.18138 0.040855 -0.113 0.24107 0.3657 -0.27525 -0.05684 0.34872 0.011884 0.14517 -0.71395 0.48497 0.14807 0.62287 0.20599 0.58379 -0.13438 0.40207 0.18311 0.28021 -0.42349 -0.25626 0.17715 -0.54095 0.16596 -0.036058 0.08499 -0.64989 0.075549 -0.28831 0.40626 -0.2802 0.094062 0.32406 0.28437 -0.26341 0.11553 0.071918 -0.47215 -0.18366 -0.34709 0.29964 -0.66514 0.002516 -0.42333 0.27512 0.36012 0.16311 0.23964 -0.05923 0.3261 0.20559 0.038677 -0.045816 0.089764 0.43151 -0.15954 0.08532 -0.26572 -0.15001 0.084286 -0.16714 -0.43004 0.060807 0.13121 -0.24112 0.66554 0.4453 -0.18019 -0.13919 0.56252 0.21457 -0.46443 -0.012211 0.029988 -0.051094 -0.20135 0.80788 0.47377 -0.057647 0.46216 0.16084 -0.20954 -0.05452 0.15572 -0.13712 0.12972 -0.011936 -0.003378 -0.13595 -0.080711 0.20065 0.054056 0.046816 0.059539 0.046265 0.17754 -0.31094 0.28119 -0.24355 0.085252 -0.21011 -0.19472 0.0027297 -0.46341 0.14789 -0.31517 -0.065939 0.036106 0.42903 -0.33759 0.16432 0.32568 -0.050392 -0.054297 0.24074 0.41923 0.13012 -0.17167 -0.37808 -0.23089 -0.019477 -0.29291 -0.30824 0.30297 -0.22659 0.081574 -0.18516 -0.21408 0.40616 -0.28974 0.074174 -0.17795 0.28595 -0.039626 -0.2339 -0.36054 -0.067503 -0.091065 0.23438 -0.0041331 0.003232 0.0072134 0.008697 0.21614 0.049904 0.35582 0.13748 0.073361 0.14166 0.2412 -0.013322 0.15613 0.083381 0.088146 -0.019357 0.43795 0.083961 0.45309 -0.50489 -0.10865 -0.2527 -0.18251 0.20441 0.13319 0.1294 0.050594 -0.15612 -0.39543 0.12538 0.24881 -0.1927 -0.31847 -0.12719 0.4341 0.31177 -0.0040946 -0.2094 -0.079961 0.1161 -0.050794 0.015266 -0.2803 -0.12486 0.23587 0.2339 -0.14023 0.028462 0.56923 -0.1649 -0.036429 0.010051 -0.17107 -0.042608 0.044965 -0.4393 -0.26137 0.30088 -0.060772 -0.45312 -0.19076 -0.20288 0.27694 -0.060888 0.11944 0.62206 -0.19343 0.47849 -0.30113 0.059389 0.074901 0.061068 -0.4662 0.40054 -0.19099 -0.14331 0.018267 -0.18643 0.20709 -0.35598 0.05338 -0.050821 -0.1918 -0.37846 -0.06589\n",
            ". 0.012001 0.20751 -0.12578 -0.59325 0.12525 0.15975 0.13748 -0.33157 -0.13694 1.7893 -0.47094 0.70434 0.26673 -0.089961 -0.18168 0.067226 0.053347 1.5595 -0.2541 0.038413 -0.01409 0.056774 0.023434 0.024042 0.31703 0.19025 -0.37505 0.035603 0.1181 0.012032 -0.037566 -0.5046 -0.049261 0.092351 0.11031 -0.073062 0.33994 0.28239 0.13413 0.070128 -0.022099 -0.28103 0.49607 -0.48693 -0.090964 -0.1538 -0.38011 -0.014228 -0.19392 -0.11068 -0.014088 -0.17906 0.24509 -0.16878 -0.15351 -0.13808 0.02151 0.13699 0.0068061 -0.14915 -0.38169 0.12727 0.44007 0.32678 -0.46117 0.068687 0.34747 0.18827 -0.31837 0.4447 -0.2095 -0.26987 0.48945 0.15388 0.05295 -0.049831 0.11207 0.14881 -0.37003 0.30777 -0.33865 0.045149 -0.18987 0.26634 -0.26401 -0.47556 0.68381 -0.30653 0.24606 0.31611 -0.071098 0.030417 0.088119 0.045025 0.20125 -0.21618 -0.36371 -0.25948 -0.42398 -0.14305 -0.10208 0.21498 -0.21924 -0.17935 0.21546 0.13801 0.24504 -0.2559 0.054815 0.21307 0.2564 -0.25673 0.17961 -0.47638 -0.25181 -0.0091498 -0.054362 -0.21007 0.12597 -0.40795 -0.021164 0.20585 0.18925 -0.0051896 -0.51394 0.28862 -0.077748 -0.27676 0.46567 -0.14225 -0.17879 -0.4357 -0.32481 0.15034 -0.058367 0.49652 0.20472 0.019866 0.13326 0.12823 -1.0177 0.29007 0.28995 0.029994 -0.10763 0.28665 -0.24387 0.22905 -0.26249 -0.069269 -0.17889 0.21936 0.15146 0.04567 -0.050497 0.071482 -0.1027 -0.080705 0.30296 0.031302 0.26613 -0.0060951 0.10313 -0.39987 -0.043945 -0.057625 0.08702 -0.098152 0.22835 -0.005211 0.038075 0.01591 -0.20622 0.021853 0.0040426 -0.043063 -0.002294 -0.26097 -0.25802 -0.28158 -0.23118 -0.010404 -0.30102 -0.4042 0.014653 -0.10445 0.30377 -0.20957 0.3119 0.068272 0.1008 0.010423 0.54011 0.29865 0.12653 0.013761 0.21738 -0.39521 0.066633 0.50327 0.14913 -0.11554 0.010042 0.095698 0.16607 -0.18808 0.055019 0.026715 -0.3164 -0.046583 -0.051591 0.023475 -0.11007 0.085642 0.28394 0.040497 0.071986 0.14157 -0.021199 0.44718 0.20088 -0.12964 -0.067183 0.47614 0.13394 -0.17287 -0.37324 -0.17285 0.02683 -0.1316 0.09116 -0.46487 0.1274 -0.090159 -0.10552 0.068006 -0.13381 0.17056 0.089509 -0.23133 -0.27572 0.061534 -0.051646 0.28377 0.25286 -0.24139 -0.19905 0.12049 -0.1011 0.27392 0.27843 0.26449 -0.18292 -0.048961 0.19198 0.17192 0.33659 -0.20184 -0.34305 -0.24553 -0.15399 0.3945 0.22839 -0.25753 -0.25675 -0.37332 -0.23884 -0.048816 0.78323 0.18851 -0.26477 0.096566 0.062658 -0.30668 -0.43334 0.10006 0.21136 0.039459 -0.11077 0.24421 0.60942 -0.46646 0.086385 -0.39702 -0.23363 0.021307 -0.10778 -0.2281 0.50803 0.11567 0.16165 -0.066737 -0.29556 0.022612 -0.28135 0.0635 0.14019 0.13871 -0.36049 -0.035\n",
            "the 0.27204 -0.06203 -0.1884 0.023225 -0.018158 0.0067192 -0.13877 0.17708 0.17709 2.5882 -0.35179 -0.17312 0.43285 -0.10708 0.15006 -0.19982 -0.19093 1.1871 -0.16207 -0.23538 0.003664 -0.19156 -0.085662 0.039199 -0.066449 -0.04209 -0.19122 0.011679 -0.37138 0.21886 0.0011423 0.4319 -0.14205 0.38059 0.30654 0.020167 -0.18316 -0.0065186 -0.0080549 -0.12063 0.027507 0.29839 -0.22896 -0.22882 0.14671 -0.076301 -0.1268 -0.0066651 -0.052795 0.14258 0.1561 0.05551 -0.16149 0.09629 -0.076533 -0.049971 -0.010195 -0.047641 -0.16679 -0.2394 0.0050141 -0.049175 0.013338 0.41923 -0.10104 0.015111 -0.077706 -0.13471 0.119 0.10802 0.21061 -0.051904 0.18527 0.17856 0.041293 -0.014385 -0.082567 -0.035483 -0.076173 -0.045367 0.089281 0.33672 -0.22099 -0.0067275 0.23983 -0.23147 -0.88592 0.091297 -0.012123 0.013233 -0.25799 -0.02972 0.016754 0.01369 0.32377 0.039546 0.042114 -0.088243 0.30318 0.087747 0.16346 -0.40485 -0.043845 -0.040697 0.20936 -0.77795 0.2997 0.2334 0.14891 -0.39037 -0.053086 0.062922 0.065663 -0.13906 0.094193 0.10344 -0.2797 0.28905 -0.32161 0.020687 0.063254 -0.23257 -0.4352 -0.017049 -0.32744 -0.047064 -0.075149 -0.18788 -0.015017 0.029342 -0.3527 -0.044278 -0.13507 -0.11644 -0.1043 0.1392 0.0039199 0.37603 0.067217 -0.37992 -1.1241 -0.057357 -0.16826 0.03941 0.2604 -0.023866 0.17963 0.13553 0.2139 0.052633 -0.25033 -0.11307 0.22234 0.066597 -0.11161 0.062438 -0.27972 0.19878 -0.36262 -1.0006e-05 -0.17262 0.29166 -0.15723 0.054295 0.06101 -0.39165 0.2766 0.057816 0.39709 0.025229 0.24672 -0.08905 0.15683 -0.2096 -0.22196 0.052394 -0.01136 0.050417 -0.14023 -0.042825 -0.031931 -0.21336 -0.20402 -0.23272 0.07449 0.088202 -0.11063 -0.33526 -0.014028 -0.29429 -0.086911 -0.1321 -0.43616 0.20513 0.0079362 0.48505 0.064237 0.14261 -0.43711 0.12783 -0.13111 0.24673 -0.27496 0.15896 0.43314 0.090286 0.24662 0.066463 -0.20099 0.1101 0.03644 0.17359 -0.15689 -0.086328 -0.17316 0.36975 -0.40317 -0.064814 -0.034166 -0.013773 0.062854 -0.17183 -0.12366 -0.034663 -0.22793 -0.23172 0.239 0.27473 0.15332 0.10661 -0.060982 -0.024805 -0.13478 0.17932 -0.37374 -0.02893 -0.11142 -0.08389 -0.055932 0.068039 -0.10783 0.1465 0.094617 -0.084554 0.067429 -0.3291 0.034082 -0.16747 -0.25997 -0.22917 0.020159 -0.02758 0.16136 -0.18538 0.037665 0.57603 0.20684 0.27941 0.16477 -0.018769 0.12062 0.069648 0.059022 -0.23154 0.24095 -0.3471 0.04854 -0.056502 0.41566 -0.43194 0.4823 -0.051759 -0.27285 -0.25893 0.16555 -0.1831 -0.06734 0.42457 0.010346 0.14237 0.25939 0.17123 -0.13821 -0.066846 0.015981 -0.30193 0.043579 -0.043102 0.35025 -0.19681 -0.4281 0.16899 0.22511 -0.28557 -0.1028 -0.018168 0.11407 0.13015 -0.18317 0.1323\n",
            "and -0.18567 0.066008 -0.25209 -0.11725 0.26513 0.064908 0.12291 -0.093979 0.024321 2.4926 -0.017916 -0.071218 -0.24782 -0.26237 -0.2246 -0.21961 -0.12927 1.0867 -0.66072 -0.031617 -0.057328 0.056903 -0.27939 -0.39825 0.14251 -0.085146 -0.14779 0.055067 -0.0028687 -0.20917 -0.070735 0.22577 -0.15881 -0.10395 0.09711 -0.56251 -0.32929 -0.20853 0.0098711 0.049777 0.0014883 0.15884 0.042771 -0.0026956 -0.02462 -0.19213 -0.22556 0.10838 0.090086 -0.13291 0.32559 -0.17038 -0.1099 -0.23986 -0.024289 0.014656 -0.237 0.084828 -0.35982 -0.076746 0.048909 0.11431 -0.21013 0.24765 -0.017531 -0.14028 0.046191 0.22972 0.1175 0.12724 0.012992 0.4587 0.41085 0.039106 0.15713 -0.18376 0.26834 0.056662 0.16844 -0.053788 -0.091892 0.11193 -0.08681 -0.13324 0.15062 -0.31733 -0.22078 0.25038 0.34131 0.36419 -0.089514 -0.22193 0.24471 0.040091 0.47798 -0.029996 0.0019212 0.063511 -0.20417 -0.26478 0.20649 0.015573 -0.27722 -0.18861 -0.10289 -0.49773 0.14986 -0.010877 0.25085 -0.28117 0.18966 -0.065879 0.094753 -0.15338 -0.055071 -0.36747 0.24993 0.096527 0.23538 0.18405 0.052859 0.22967 0.12582 0.15536 -0.17275 0.33946 -0.10049 0.074948 -0.093575 -0.04049 -0.016922 -0.0058039 -0.18108 0.19537 0.45178 0.10965 0.2337 -0.09905 -0.078633 0.21678 -0.71231 -0.099759 0.33333 -0.1646 -0.091688 0.21056 0.023669 0.028922 0.1199 -0.12512 -0.026037 -0.062217 0.55816 0.0050273 -0.30888 0.038611 0.17568 -0.11163 -0.10815 -0.19444 0.29433 0.14519 -0.042878 0.18534 0.018891 -0.61883 0.13352 0.036007 0.33995 0.22109 -0.079328 0.071319 0.17678 0.16378 -0.23142 -0.1434 -0.098122 -0.019286 0.2356 -0.34013 -0.061007 -0.23208 -0.31152 0.10063 -0.15957 0.20183 -0.016345 -0.12303 0.022667 -0.20986 -0.20127 -0.087883 0.064731 0.10195 -0.1786 0.33056 0.21407 -0.32165 -0.17106 0.19407 -0.38618 -0.2148 -0.052254 0.023175 0.47389 0.18612 0.12711 0.20855 -0.10256 -0.12016 -0.40488 0.029695 -0.027419 -0.0085227 -0.11415 0.081134 -0.17228 0.19142 0.026514 0.043789 -0.12399 0.13354 0.10112 0.081682 -0.15085 0.0075806 -0.18971 0.24669 0.22491 0.35553 -0.3277 -0.21821 0.1402 0.28604 0.055226 -0.086544 0.02111 -0.19236 0.074245 0.076782 0.00081666 0.034097 -0.57719 0.10657 0.28134 -0.11964 -0.68281 -0.32893 -0.24442 -0.025847 0.0091273 0.2025 -0.050959 -0.11042 0.010962 0.076773 0.40048 -0.40739 -0.44773 0.31954 -0.036326 -0.012789 -0.17282 0.1476 0.2356 0.080642 -0.36528 -0.0083443 0.6239 -0.24379 0.019917 -0.28803 -0.010494 0.038412 -0.11718 -0.072462 0.16381 0.38488 -0.029783 0.23444 0.4532 0.14815 -0.027021 -0.073181 -0.1147 -0.0054545 0.47796 0.090912 0.094489 -0.36882 -0.59396 -0.097729 0.20072 0.17055 -0.0047356 -0.039709 0.32498 -0.023452 0.12302 0.3312\n",
            "to 0.31924 0.06316 -0.27858 0.2612 0.079248 -0.21462 -0.10495 0.15495 -0.03353 2.4834 -0.50904 0.08749 0.21426 0.22151 -0.25234 -0.097544 -0.1927 1.3606 -0.11592 -0.10383 0.21929 0.11997 -0.11063 0.14212 -0.16643 0.21815 0.0042086 -0.070012 -0.23532 -0.26518 0.031248 0.16669 -0.089777 0.20059 0.31614 -0.5583 0.075735 0.27635 0.12741 -0.18185 -0.12722 0.024686 -0.077233 -0.48998 0.020355 0.0039164 0.1215 0.089723 -0.078975 0.081443 -0.099087 -0.055621 0.10737 -0.0044042 0.48496 0.11717 -0.017329 0.109 -0.35558 0.051084 0.15714 0.17961 -0.29711 0.033645 -0.025792 -0.013931 -0.23 -0.040306 0.22282 -0.013544 0.011554 0.3911 0.26533 -0.31012 0.40539 -0.042975 0.020811 -0.33033 0.19573 -0.037958 0.10274 -0.0013581 -0.44505 0.077886 0.08511 -0.20285 -0.19481 0.056933 0.53105 0.034154 -0.56996 -0.18469 0.093403 0.28044 -0.23349 0.10938 -0.014288 -0.274 0.034196 -0.098479 0.13268 0.19437 0.13463 -0.099059 0.040324 -0.66272 0.3571 0.15429 0.18598 0.087542 0.080538 -0.25121 0.24155 0.1783 0.036011 -0.027677 0.21161 -0.29107 -0.0083456 0.11317 0.31064 -0.10693 -0.27367 -0.039785 0.039881 0.034462 -0.16518 0.16115 0.060826 0.3075 -0.22398 0.14619 -0.2661 0.49732 -0.13996 -0.24287 0.039469 -0.084495 -0.24315 0.070701 -1.0136 -0.21733 -0.36878 -0.24973 0.17472 -0.011592 0.068561 -0.090411 0.21878 -0.2639 0.11904 0.14285 -0.18707 -0.13474 -0.13232 -0.26553 0.22947 -0.018215 0.0067383 -0.1019 0.10053 -0.1127 -0.13295 0.15951 0.14906 -0.095578 0.26992 0.011057 0.056568 0.021386 0.20215 0.00048589 0.5336 -0.22947 0.29275 0.17378 0.25423 -0.10976 0.058816 0.014616 -0.04306 0.10732 -0.028149 -0.19181 0.1025 -0.063892 0.012737 -0.12913 0.015037 0.26562 -0.017049 -0.060716 -0.094919 0.017775 0.13221 0.1683 -0.19323 -0.17612 0.075506 0.18939 0.12508 -0.1988 -0.16017 -0.21092 0.46933 0.044747 0.098349 0.011637 0.22281 -0.010837 -0.04833 -0.47335 -0.36811 -0.13592 -0.15086 0.25416 0.069531 0.14211 -0.26703 -0.1259 0.12076 -0.26117 0.033024 -0.034398 -0.13968 0.13446 -0.16709 0.15002 -0.13724 0.091226 -0.27718 0.020098 0.26919 0.43016 0.094019 -0.085496 -0.25192 -0.11645 -0.039734 0.0046738 0.54178 -0.16636 0.34546 0.098501 0.47819 -0.38428 -0.3238 -0.14822 -0.47817 0.16704 -0.064505 0.11834 -0.3448 0.096891 0.32309 0.41471 0.19463 -0.20891 -0.12223 -0.058298 -0.20268 0.2948 0.043397 0.10112 0.27177 -0.52124 -0.073794 0.044808 0.41388 0.088782 0.62255 -0.072391 0.090129 0.15428 0.023163 -0.13028 0.061762 0.33803 -0.091581 0.21039 0.05108 0.19184 0.10444 0.2138 -0.35091 -0.23702 0.038399 -0.10031 0.18359 0.025178 -0.12977 0.3713 0.18888 -0.0042738 -0.10645 -0.2581 -0.044629 0.082745 0.097801 0.25045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xjzFKAiMjFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_index = dict()\n",
        "\n",
        "with open(embedding_path, 'r') as fp:\n",
        "    for line in fp:\n",
        "        values = line.strip().split(' ')\n",
        "        word = values[0]\n",
        "        embedding = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index[word] = embedding\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "\n",
        "embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: \n",
        "        continue\n",
        "        \n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    \n",
        "    if embedding_vector is not None: \n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds0cX_FQHenX",
        "colab_type": "text"
      },
      "source": [
        "### Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4CqXUboZJkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "def embedding_test(embed_size, embedding_matrix):\n",
        "    return tf.keras.Sequential([\n",
        "        Embedding(max_features, embed_size, weights = [embedding_matrix], trainable = False)              \n",
        "    ])\n",
        "\n",
        "emb = embedding_test(embed_size, embedding_matrix)\n",
        "emb(x_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTKns9gcHb7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from tensorflow.keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "\n",
        "def create_model_baseline(lr, nr_classes, max_features, embed_size, embedding_matrix, dropout=0.0, lr_decay=0.0):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, embed_size, weights = [embedding_matrix], trainable = False))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Conv1D(250, 3, padding='valid', activation='relu'))\n",
        "    model.add(GlobalAveragePooling1D())\n",
        "    model.add(Dense(250, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(nr_classes, activation='sigmoid'))\n",
        "    \n",
        "    model.compile(loss = \"binary_crossentropy\", \n",
        "                  optimizer = tf.keras.optimizers.Adam(lr = lr, decay = lr_decay), \n",
        "                  metrics = [\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_model_baseline2():\n",
        "    seq = Input(shape=(max_len,), name='seq')\n",
        "    l = Embedding(max_features, embedding_dims, weights=[embedding_matrix])(seq)\n",
        "    l = SpatialDropout1D(0.4)(l)\n",
        "    c2 = Conv1D(embedding_dims,2, activation='relu')(l)\n",
        "    c3 = Conv1D(embedding_dims,3, activation='relu')(l)\n",
        "    c4 = Conv1D(embedding_dims,4, activation='relu')(l)\n",
        "    c5 = Conv1D(embedding_dims,5, activation='relu')(l)\n",
        "    max_pool2 = GlobalMaxPooling1D()(c2)\n",
        "    max_pool3 = GlobalMaxPooling1D()(c3)\n",
        "    max_pool4 = GlobalMaxPooling1D()(c4)\n",
        "    max_pool5 = GlobalMaxPooling1D()(c5)\n",
        "    conc = concatenate([max_pool2,max_pool3,max_pool4,max_pool5])\n",
        "    conc = Dense(36)(conc)\n",
        "    output = Dense(6, activation='sigmoid', name='output')(conc)\n",
        "    \n",
        "    model = Model(inputs=[seq], outputs=output)\n",
        "    \n",
        "    model.compile(loss = \"binary_crossentropy\", \n",
        "              optimizer = tf.keras.optimizers.Adam(lr = lr, decay = lr_decay), \n",
        "              metrics = [\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def create_model_baseline3(lr, nr_classes, max_features, embed_size, embedding_matrix):\n",
        "    inp = Input(shape = (max_len,))\n",
        "    x = Embedding(max_features, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
        "    x= Conv1D(128, 3, activation='relu')(x)\n",
        "    x = MaxPooling1D(3)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Conv1D(64, 3, activation='relu')(x)\n",
        "    x = MaxPooling1D(3)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Conv1D(64, 3, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    x = concatenate([avg_pool, max_pool])\n",
        "    x = keras.layers.Dropout(0.2)(x)\n",
        "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = keras.layers.Dropout(0.2)(x)\n",
        "    output = keras.layers.Dense(nr_classes, activation=\"sigmoid\")(x)\n",
        "    \n",
        "    model = Model(inputs=inp, outputs=output)\n",
        "\n",
        "    \n",
        "    model.compile(loss = \"binary_crossentropy\", \n",
        "                  optimizer = tf.keras.optimizers.Adam(lr), \n",
        "                  metrics = [\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_model(lr, nr_classes, max_features, embed_size, embedding_matrix, gru_units=128, dropout=0.0, lr_decay=0.0):\n",
        "    inp = Input(shape = (max_len,))\n",
        "    # x = Embedding(max_features, embed_size, trainable = True)(inp)\n",
        "    x = Embedding(max_features, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
        "    x = SpatialDropout1D(dropout)(x)\n",
        "    x = Bidirectional(GRU(gru_units, return_sequences = True))(x)\n",
        "    x = Conv1D(64, kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    x = concatenate([avg_pool, max_pool])\n",
        "    #x = keras.layers.Dropout(dropout)(x)\n",
        "    #x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    # x = keras.layers.Dropout(dropout)(x)\n",
        "    x = keras.layers.Dense(nr_classes, activation=\"sigmoid\")(x)\n",
        "    \n",
        "    model = Model(inputs = inp, outputs = x)\n",
        "    model.compile(loss = \"binary_crossentropy\", \n",
        "                  optimizer = tf.keras.optimizers.Adam(lr = lr, decay = lr_decay), \n",
        "                  metrics = [\"accuracy\"])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV_ihYNwIAdp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "5d53c488-e816-47b0-abde-86981fa08306"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "class RocAucEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n",
        "\n",
        "\n",
        "ra_val = RocAucEvaluation(validation_data=(x_val, y_val), interval = 1)\n",
        "\n",
        "model = create_model(lr=1e-3, nr_classes=len(label_cols), max_features=max_features, embed_size=embed_size, embedding_matrix=embedding_matrix, dropout=0.2)\n",
        "# model = create_model_baseline(lr=1e-3, nr_classes=len(label_cols), max_features=max_features, embed_size=embed_size, embedding_matrix=embedding_matrix, dropout=0.2)\n",
        "\n",
        "history = model.fit(x_train, \n",
        "                    y_train, \n",
        "                    batch_size = 128, \n",
        "                    epochs = 4, \n",
        "                    validation_data = (x_val, y_val), \n",
        "                    verbose = 1, \n",
        "                    callbacks = [ra_val])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 143613 samples, validate on 15958 samples\n",
            "Epoch 1/4\n",
            "143488/143613 [============================>.] - ETA: 1s - loss: 0.0550 - accuracy: 0.9802\n",
            " ROC-AUC - epoch: 1 - score: 0.986031\n",
            "143613/143613 [==============================] - 1873s 13ms/sample - loss: 0.0550 - accuracy: 0.9802 - val_loss: 0.0455 - val_accuracy: 0.9827\n",
            "Epoch 2/4\n",
            "143488/143613 [============================>.] - ETA: 1s - loss: 0.0430 - accuracy: 0.9835\n",
            " ROC-AUC - epoch: 2 - score: 0.987890\n",
            "143613/143613 [==============================] - 1878s 13ms/sample - loss: 0.0430 - accuracy: 0.9835 - val_loss: 0.0431 - val_accuracy: 0.9831\n",
            "Epoch 3/4\n",
            "143488/143613 [============================>.] - ETA: 1s - loss: 0.0399 - accuracy: 0.9844\n",
            " ROC-AUC - epoch: 3 - score: 0.988351\n",
            "143613/143613 [==============================] - 1866s 13ms/sample - loss: 0.0400 - accuracy: 0.9843 - val_loss: 0.0427 - val_accuracy: 0.9836\n",
            "Epoch 4/4\n",
            "143488/143613 [============================>.] - ETA: 1s - loss: 0.0375 - accuracy: 0.9853\n",
            " ROC-AUC - epoch: 4 - score: 0.988833\n",
            "143613/143613 [==============================] - 1874s 13ms/sample - loss: 0.0375 - accuracy: 0.9853 - val_loss: 0.0421 - val_accuracy: 0.9836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38kmLA7U9VO3",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hJtmDT1w1nR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_test, batch_size=128, verbose=0)\n",
        "\n",
        "df_pred = pd.DataFrame(y_pred, columns=label_cols)\n",
        "idxs_used_for_eval = df_test_labels[df_test_labels['toxic'] != -1].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOwm0cAl0Y1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "81e82a48-cea6-4aeb-d0f3-345dd7ecf0dd"
      },
      "source": [
        "roc_auc_score(df_test_labels.loc[idxs_used_for_eval, label_cols], y_pred[idxs_used_for_eval])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9823886064926209"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LEleuwS0igu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "84255032-1383-4bdd-9cfa-7782a4bf49c3"
      },
      "source": [
        "subm = pd.read_csv(subm_path)\n",
        "\n",
        "submid = pd.DataFrame({'id': subm[\"id\"]})\n",
        "submission = pd.concat([submid, pd.DataFrame(y_pred, columns = label_cols)], axis=1)\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "!kaggle competitions submit -c jigsaw-toxic-comment-classification-challenge -f submission.csv -m \"gru-cnn\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 13.7M/13.7M [00:04<00:00, 3.37MB/s]\n",
            "Successfully submitted to Toxic Comment Classification Challenge"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFh4pNpzUDL7",
        "colab_type": "text"
      },
      "source": [
        "## Deep Learning Approach 2: BERT Transfer Learning\n",
        "\n",
        "For multiclass classification, use sigmoid instead of softmax as output layer, combined with sigmoid_cross_entropy_with_logits loss?\n",
        "\n",
        "Use fast.ai library (based on PyTorch) - much easier than with Tensorflow.\n",
        "\n",
        "Main sources: https://github.com/huggingface/transformers/blob/04c69db399b2ab9e3af872ce46730fbd9f17aec3/examples/run_tf_glue.py\n",
        "\n",
        "[Sequence Classification with Transformers](https://colab.research.google.com/drive/1l39vWjZ5jRUimSQDoUcuWGIoNjLjA2zu#scrollTo=8aihC2QV6IXk)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i57-ZkxblBx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f396798e-4aef-4ba7-8f2a-4dd5b0a211e2"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "  # Load the TensorBoard extension\n",
        "  %load_ext tensorboard\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "def1RjYgXtGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "6e3ae28d-a6b2-46c3-a5ec-7f0c0dfba361"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f9/51824e40f0a23a49eab4fcaa45c1c797cbf9761adedd0b558dab7c958b34/transformers-2.1.1-py3-none-any.whl (311kB)\n",
            "\r\u001b[K     |█                               | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /tensorflow-2.0.0/python3.6 (from transformers) (2.22.0)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.0.0/python3.6 (from transformers) (1.17.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.14)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 38.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 39.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.0.0/python3.6 (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.0.0/python3.6 (from requests->transformers) (1.25.7)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.0.0/python3.6 (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.0.0/python3.6 (from requests->transformers) (2019.9.11)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.14 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.14)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: six in /tensorflow-2.0.0/python3.6 (from sacremoses->transformers) (1.13.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=36880f3d318f1f3d66a59e2ef636dc397ffc6ae00ace601a078047e2aa8e6f15\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: regex, sacremoses, sentencepiece, transformers\n",
            "Successfully installed regex-2019.11.1 sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsAZlZkpcHo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification, BertConfig, glue_convert_examples_to_features, BertForSequenceClassification, glue_processors\n",
        "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwu6joWyWGk3",
        "colab_type": "text"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qVOyWMrotXm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "9ecbb501-bb97-48cc-b77c-bab812e1c527"
      },
      "source": [
        "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "df = pd.read_csv(train_path)\n",
        "nr_train_samples = int(0.9*len(df))\n",
        "\n",
        "df_train = df.iloc[:nr_train_samples]\n",
        "df_val = df.iloc[nr_train_samples:]\n",
        "\n",
        "df_train.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN1v4agj0Uzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "ccd0ed4d-d682-4253-df88-0e5ebf586553"
      },
      "source": [
        "df_train = df_train.sample(100)\n",
        "df_val = df_val.sample(100)\n",
        "\n",
        "comment_lens = df_train.comment_text.str.count(' ') + 1\n",
        "comment_lens.hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9fcfe492b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgSGiTwmL_UR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "d132dd75-8e44-4f0a-8547-21fe618f4ad4"
      },
      "source": [
        "df_train = df_train.loc[df_train.comment_text.str.count(' ') + 1 < 220]\n",
        "df_val = df_val.loc[df_val.comment_text.str.count(' ') + 1 < 220]\n",
        "\n",
        "comment_lens = df_train.comment_text.str.count(' ') + 1\n",
        "comment_lens.hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9fcc729780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAiCkUUWXOKOcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keAf735-2ZYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import InputFeatures, InputExample\n",
        "\n",
        "def convert_examples_to_features(examples, tokenizer,\n",
        "                                max_length=512,\n",
        "                                pad_on_left=False,\n",
        "                                pad_token=0,\n",
        "                                pad_token_segment_id=0,\n",
        "                                mask_padding_with_zero=True):\n",
        "    \"\"\"\n",
        "    Note: Just adapted the function glue_convert_examples_to_features, \n",
        "    to support tensors as label instead of scalar\n",
        "    \"\"\"\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        example = InputExample(example['idx'].numpy(),\n",
        "                            example['sentence1'].numpy().decode('utf-8'),\n",
        "                            example['sentence2'].numpy().decode('utf-8'),\n",
        "                            example['label'].numpy())\n",
        "\n",
        "        inputs = tokenizer.encode_plus(\n",
        "            example.text_a,\n",
        "            example.text_b,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "        )\n",
        "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding_length = max_length - len(input_ids)\n",
        "        if pad_on_left:\n",
        "            input_ids = ([pad_token] * padding_length) + input_ids\n",
        "            attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask\n",
        "            token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids\n",
        "        else:\n",
        "            input_ids = input_ids + ([pad_token] * padding_length)\n",
        "            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)\n",
        "\n",
        "        assert len(input_ids) == max_length, \"Error with input length {} vs {}\".format(len(input_ids), max_length)\n",
        "        assert len(attention_mask) == max_length, \"Error with input length {} vs {}\".format(len(attention_mask), max_length)\n",
        "        assert len(token_type_ids) == max_length, \"Error with input length {} vs {}\".format(len(token_type_ids), max_length)\n",
        "\n",
        "        label = example.label\n",
        "\n",
        "        features.append(\n",
        "                InputFeatures(input_ids=input_ids,\n",
        "                              attention_mask=attention_mask,\n",
        "                              token_type_ids=token_type_ids,\n",
        "                              label=label))\n",
        "\n",
        "    def gen():\n",
        "        for ex in features:\n",
        "            yield  ({'input_ids': ex.input_ids,\n",
        "                    'attention_mask': ex.attention_mask,\n",
        "                    'token_type_ids': ex.token_type_ids},\n",
        "                    ex.label)\n",
        "            \n",
        "    return tf.data.Dataset.from_generator(gen,\n",
        "        ({'input_ids': tf.int32,\n",
        "            'attention_mask': tf.int32,\n",
        "            'token_type_ids': tf.int32},\n",
        "            tf.int64),\n",
        "        ({'input_ids': tf.TensorShape([None]),\n",
        "            'attention_mask': tf.TensorShape([None]),\n",
        "            'token_type_ids': tf.TensorShape([None])},\n",
        "            tf.TensorShape([None])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNeoOBXRqeS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_example(id, sentence, label):\n",
        "    return {'idx': tf.dtypes.cast(id, tf.dtypes.int32), 'label': label, 'sentence1': sentence, 'sentence2': \"\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NS9rSuqrA_qh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "10a265e2-ef47-4b3e-fca9-7c5c0037e0f4"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((df_train.index.values, df_train['comment_text'].values, df_train[label_cols].values))\n",
        "train_dataset = train_dataset.map(convert_to_example)\n",
        "\n",
        "train_dataset = convert_examples_to_features(train_dataset, tokenizer, 220)\n",
        "\n",
        "for data, label in train_dataset.take(1):\n",
        "    print(label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 213450/213450 [00:00<00:00, 389333.78B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 0 0 0 0 0], shape=(6,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np4UmWMNCA29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "class RocAucEvaluation(Callback):\n",
        "    def __init__(self, validation_dataset, interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "\n",
        "        self.interval = interval\n",
        "        self.val_dataset = validation_dataset\n",
        "        all_labels = []\n",
        "        for f, labels in validation_dataset:\n",
        "            all_labels.append(labels.numpy())\n",
        "\n",
        "        self.all_labels = np.concatenate(all_labels, axis=0)\n",
        "        \n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.val_dataset, verbose=0)\n",
        "            for i in range(y_pred.shape[1]):\n",
        "                score = roc_auc_score(self.all_labels[:,i], y_pred[:,i])\n",
        "                print(\"\\n i ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy_AHY8ljENC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "84849b7a-2203-4e99-ae5d-7325664b949e"
      },
      "source": [
        "# script parameters\n",
        "BATCH_SIZE = 16\n",
        "EVAL_BATCH_SIZE = BATCH_SIZE\n",
        "USE_XLA = False\n",
        "USE_AMP = False\n",
        "EPOCHS = 5\n",
        "\n",
        "num_labels = 6\n",
        "\n",
        "tf.config.optimizer.set_jit(USE_XLA)\n",
        "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": USE_AMP})\n",
        "\n",
        "# Load tokenizer and model from pretrained model/vocabulary. Specify the number of labels to classify (2+: classification, 1: regression)\n",
        "config = BertConfig.from_pretrained(\"bert-base-cased\", num_labels=num_labels)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-cased', config=config)\n",
        "\n",
        "# Create Data Pipeline\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((df_train.index.values, df_train['comment_text'].values, df_train[label_cols].values))\n",
        "train_dataset = train_dataset.map(convert_to_example)\n",
        "\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((df_val.index.values, df_val['comment_text'].values, df_val[label_cols].values))\n",
        "valid_dataset = valid_dataset.map(convert_to_example)\n",
        "\n",
        "train_examples = len(df_train)\n",
        "valid_examples = len(df_val)\n",
        "\n",
        "train_dataset = convert_examples_to_features(train_dataset, tokenizer, 220)\n",
        "valid_dataset = convert_examples_to_features(valid_dataset, tokenizer, 220)\n",
        "\n",
        "train_dataset = train_dataset.shuffle(128).batch(BATCH_SIZE).repeat(-1)\n",
        "valid_dataset = valid_dataset.batch(EVAL_BATCH_SIZE)\n",
        "\n",
        "ra_val = RocAucEvaluation(validation_dataset=valid_dataset, interval = 1)\n",
        "\n",
        "# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule \n",
        "opt = tf.keras.optimizers.Adam(learning_rate=3e-4, epsilon=1e-08)\n",
        "\n",
        "# Loss: TFBertForSequenceClassification has no sigmoid activation in output layer --> set from_logits=True\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train and evaluate using tf.keras.Model.fit()\n",
        "train_steps = train_examples//BATCH_SIZE\n",
        "valid_steps = valid_examples//EVAL_BATCH_SIZE\n",
        "\n",
        "history = model.fit(train_dataset, \n",
        "                    epochs=EPOCHS, \n",
        "                    steps_per_epoch=train_steps,\n",
        "                    validation_data=valid_dataset, \n",
        "                    validation_steps=valid_steps, \n",
        "                    callbacks = [ra_val])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 5 steps, validate for 5 steps\n",
            "Epoch 1/5\n",
            "4/5 [=======================>......] - ETA: 7s - loss: 0.4684 - accuracy: 0.9375 \n",
            " i ROC-AUC - epoch: 1 - score: 0.645503\n",
            "\n",
            " i ROC-AUC - epoch: 1 - score: 0.836957\n",
            "\n",
            " i ROC-AUC - epoch: 1 - score: 0.455556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-a8e75f453812>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                     callbacks = [ra_val])\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m                       total_epochs=1)\n\u001b[1;32m    371\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m--> 372\u001b[0;31m                                  prefix='val_')\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    683\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-6e09f8612060>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n i ROC-AUC - epoch: {:d} - score: {:.6f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    353\u001b[0m     return _average_binary_score(\n\u001b[1;32m    354\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    324\u001b[0m                              \"is not defined in that case.\")\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0ougRCeOzUo",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUYiQJNMPjIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = pd.read_csv(test_path)\n",
        "df_test_labels = pd.read_csv(test_labels_path)\n",
        "df_test = pd.concat([df_test, df_test_labels], axis=1)\n",
        "df_test = df_test[df_test['toxic'] != -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYRualnIPrnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = df_test.sample(2000)\n",
        "df_test['comment_text'] = df_test['comment_text'].str.slice(0,512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qJMhf1CO0iZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_batch_size = 8\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((df_test.index.values, df_test['comment_text'].values, df_test[label_cols].values))\n",
        "test_dataset = test_dataset.map(convert_to_example)\n",
        "\n",
        "test_dataset = convert_examples_to_features(test_dataset, tokenizer, 512)\n",
        "test_dataset = test_dataset.batch(test_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QpkceTQc0lV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "683aa434-d80d-464e-c371-11f6480c4699"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_pred = model.predict(test_dataset, verbose=1, workers=4, steps=len(df_test)//test_batch_size)\n",
        "y_pred = tf.keras.activations.sigmoid(y_pred)\n",
        "\n",
        "roc_auc_score(df_test[label_cols], y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 52s 209ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7013244147372028"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    }
  ]
}